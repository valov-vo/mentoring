# Хакатон по исследованию LinkedIn от Яндекс Практикума - команда Super 8

[КОММЕНТАРИЙ: данный файл содержит информацию по состоянию на 1 июля и будет окончательно обновлен после завершения хакатона 5 июля.]

В  репозитарии собраны материалы команды Super 8 - участника хакатона по исследованию LinkedIn от Яндекс Практикума.

## Задача

- **Заказчик**: сервис онлайн-образования (edTech)
- **Общее описание задачи**: провести исследование по теме наставничества и менторства на основании постов целевой аудитории в LinkedIn
- **Цели исследования**:
  - определить топ-10 тем в направлении наставничества на основании наибольшего охвата, используя теги: `наставничество`, `менторство`, `коучинг`, `mentorship`, `mentor`, `coaching`, `buddy`
  - определить топ-10 популярных тем по просмотрам, реакциям: лайкам, комментариям, репостам среди IT-специалистов, подходящих под описание целевой аудитории исследования
  - дополнить профили целевой аудитории новыми параметрами
- **Тип задачи**: `кластеризация`, `парсинг` `NLP`, `topic modeling`
- **Стек**:
  - парсинг: `Beautiful Soup`, `Selenium`
  - предобработка данных: `ast`, `NLTK`, `NumPy`, `pandas`, `spaCy`
  - EDA: `Matplotlib`, `seaborn`
  - topic modeling: `scikit-learn`
 
## Команда

- **Менеджер проекта**: [Александр Горлов](https://www.linkedin.com/in/alexgorlov)
- **Специалисты Data Science**:
  - [Валерий Валов](https://github.com/valov-vo)
  - [Кирилл Рубашевский](https://github.com/kirill-rubashevskiy)
  - [Александр Семенов](https://github.com/Ptolemey98)
- **IT-рекрутер**: [Лидия Селеменова](https://www.linkedin.com/in/%D0%BB%D0%B8%D0%B4%D0%B8%D1%8F-%D1%81%D0%B5%D0%BB%D0%B5%D0%BC%D0%B5%D0%BD%D0%B5%D0%B2%D0%B0-14488bb5)

## Этапы работы

Работа над хакатоном включала 5 этапов:

1. Доработка парсера
2. Парсинг данных
3. Предобработка и объединение данных
4. Topic modeling
5. Анализ данных

## Доработка парсера

На данном этапе мы доработали парсер, код которого был предложен организаторам хакатона.

В числе наших нововведений:

- парсинг только тех постов, которые содержат текст владельца анкеты (т.е. пусты репосты не парсятся);
- парсинг предыдущего опыта, количества комментариев и ссылок на посты;
- рандомизация времени пауз между действиями парсера (снижает вероятность обнаружения парсера сайтом);
- сохранение промежуточных результатов (ссылок на профили, сохранение после каждых десяти обработанных анкет);
- возможность возобновить работу парсера с места предыдущей остановки).

Файл доработанного парсера `parser.py` доступен в папке `mentoring/src/`.

## Парсинг данных

На данном этапе мы провели парсинг данных. 

В ходе парсинга мы собрали информацию о 239 анкетах и 118 постах (у части отсмотренных анкет было 0 постов, количество анкет с минимум одним постом - 51). 

Мы обратили внимание, что большинство анкет не содержат постов.

Количество собранных данных также обусловлено тем, что участвующие в парсинге DS использовали реальные профили на сайте и получили предупреждения от сайта о недопустимости использования парсера.

Собранные командой данные доступны в папке `mentoring/src/parsed-data/`.

## Предобработка и объединение данных

На данном этапе мы провели предобработку данных, собранных самостоятельно, а также данных, предоставленных участвующими в обмене командами:

- удалили нерелевантные анкеты;
- унифицировали столбцы;
- сохранили посты в отдельные строки;
- заполнили пропуски;
- объединили датасеты;
- убрали дубликаты;
- разделили объединенные данные на два датасета: датасет только с постами для Topic modeling и датасет с информацией об анкетах для IT-рекрутера.

Предобработанные данные доступны в папке `mentoring/src/preprocessed-data/`.
Процесс предобработки описан в ноутбуке `posts_preprocessing.ipynb` по адресу: `mentoring/notebooks/`.

## Topic modeling

Процесс и результаты topic modeling описаны в ноутбуке `team_8_topic_modeling.ipynb` по адресу: `mentoring/notebooks/`.

## Анализ данных

КОММЕНТАРИЙ: раздел будет заполнен 5 июля.
